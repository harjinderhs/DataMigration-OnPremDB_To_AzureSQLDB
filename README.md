# ğŸ“Œ Data Migration: On-Prem SQL DB to Azure SQL DB

## ğŸš€ Project Overview
This project demonstrates **Incremental Data Migration** from an **On-Prem SQL Database** to **Azure SQL Database** using **Azure Synapse Analytics**. The data is first transferred to **Azure Data Lake Storage Gen2 (ADLS Gen2)** and then processed using different loading techniques before being stored in Azure SQL DB.

## ğŸ“‚ Source Tables Used
The following five tables were used for this migration:
- ğŸ“š **Books**  
- ğŸ‘¥ **Members**  
- ğŸ“– **BorrowRecords**  
- ğŸ“¦ **Inventory**  
- ğŸ¢ **Librarians**  

## ğŸ”„ Data Movement Process
1ï¸âƒ£ **On-Prem SQL DB â¡ ADLS Gen2 Storage** (Incremental Load)  
2ï¸âƒ£ **ADLS Gen2 Storage â¡ Azure SQL DB** (Using Azure Synapse Pipelines)  

## âš™ï¸ Data Loading Methodologies
Three different methods were used to process data from **ADLS Gen2** to **Azure SQL DB**:
- ğŸ”¹ **Normal Data Load** â€“ For *BorrowRecords, Inventory, and Librarians*.
- ğŸ”¹ **SCD Type 1 (Slowly Changing Dimension â€“ Type 1)** â€“ For *Books* (Overwrites existing records).
- ğŸ”¹ **SCD Type 2 (Slowly Changing Dimension â€“ Type 2)** â€“ For *Members* (Keeps historical records).

## ğŸ—ï¸ Pipeline Architecture
The **Azure Synapse Analytics Pipeline** consists of the following activities:

### ğŸ”„ **Incremental Data Load: On-Prem SQL DB â¡ ADLS Gen2**
- **Set Variable Activity** â€“ Stores file name with a timestamp ğŸ“Œ
- **Lookup Activities** (2x) â€“
  - One to fetch watermark table ğŸ“Š
  - Another to find max value in source tables ğŸ”
- **Foreach Activity** â€“ Iterates through tables fetched from the watermark lookup ğŸ”„
- **Copy Activity** â€“ Moves data from On-Prem SQL DB to ADLS Gen2 Storage ğŸ“‚

### ğŸš€ **Data Processing & Load: ADLS Gen2 â¡ Azure SQL DB**
- **IF Condition Activity** â€“ Ensures only non-SCD tables are loaded normally âš¡
- **Copy Activity** â€“ Loads data from ADLS Gen2 to Azure SQL DB (for normal tables) ğŸ”„
- **Stored Procedure Activity** â€“ Updates the watermark table with the latest max value ğŸ› ï¸
- **Data Flow Activity (2x)** â€“ Implements **SCD Type 1 & Type 2** transformations ğŸš€

## ğŸ† Key Takeaways
âœ… **Incremental Data Loading** ensures efficient data migration ğŸ“Š  
âœ… **Optimized ETL process** using different data loading strategies âš™ï¸  
âœ… **Robust Pipeline Architecture** with Azure Synapse Analytics ğŸ”„  

## ğŸš€ How to Run the Project
### 1ï¸âƒ£ Prerequisites
- Azure Subscription
- On-Prem SQL Server with required tables
- Azure Data Lake Storage Gen2
- Azure Synapse Analytics
- Azure SQL Database

### 2ï¸âƒ£ Steps to Execute
1. Set up the **On-Prem SQL DB** and load the sample data.
2. Configure **Azure Data Factory / Synapse Pipeline** for incremental load.
3. Execute the pipeline to load data into **ADLS Gen2 Storage**.
4. Process the data into **Azure SQL DB** using different ETL strategies.
5. Verify the data using **SQL Queries**.

## ğŸ“§ Contact & Feedback
If you have any questions or feedback, feel free to connect with me on LinkedIn or open an issue in this repository. Letâ€™s collaborate! ğŸ’¬

#Azure #DataEngineering #AzureSynapse #SQL #ETL #CloudMigration #AzureDataFactory #ADLSGen2 #DataTransformation
